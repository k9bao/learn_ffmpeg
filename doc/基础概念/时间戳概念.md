# 1. pts/dts

- [1. pts/dts](#1-ptsdts)
  - [1.1. 概念](#11-概念)
  - [1.2. 度量时间](#12-度量时间)

## 1.1. 概念

- DTS、PTS 的概念如下所述
  - DTS（Decoding Time Stamp）：即解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。
  - PTS（Presentation Time Stamp）：即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。

## 1.2. 度量时间

- PTS和DTS的时间基,PST和DTS的单位是什么?
  - ffmpeg 里的 time_base 一般使用 AVRational{num, den}，比如 {1,90000} ,这里表示 1/90000 秒
  - AVPacket(编码数据)， AVStream.time_base
  - AVFrame(原始数据)， AVCodecContext.time_base
  - av_q2d(AVRational) --> 返回 a.num / (double) a.den; 表示一个刻度占几秒
  - timestamp(秒) = pts * av_q2d(st->time_base)
  - ffmpeg内部的时间戳 = AV_TIME_BASE * time(秒)
  - AV_TIME_BASE_Q=1/AV_TIME_BASE
  - av_rescale_q(int64_t a, AVRational bq, AVRational cq) `a*bq/cq`， bq下的占a个格子，在cq下是多少。
  - av_packet_rescale_ts(packet, AVStream.time_base, AVCodecContext.time_base)
    - 将 package 中的 timestamps / durations 转换为 AVFrame 需要的时间基
    - AVStream.time_base 是 AVPackage 的时间基
    - AVCodecContext.time_base 是 AVFrame 的时间基
  - av_packet_rescale_ts(pPacket, pStream->time_base, AV_TIME_BASE_Q);
    - 将 package 中的 timestamps / durations 转换为微妙
  - av_packet_rescale_ts(pPacket, AV_TIME_BASE_Q, AVCodecContext->time_base);
    - 将 package 中的 timestamps / durations 转换为 微妙 -》fil AVFrame 需要的时间基

&emsp;&emsp;为了回答这个问题，先引入FFmpeg中时间基的概念，也就是time_base。它也是用来度量时间的。如果把1秒分为25等份，你可以理解就是一把尺，那么每一格表示的就是1/25秒。此时的time_base={1，25}。如果你是把1秒分成90000份，每一个刻度就是1/90000秒，此时的time_base={1，90000}。

&emsp;&emsp;所谓时间基表示的就是每个刻度是多少秒

pts的值就是占多少个时间刻度（占多少个格子）。它的单位不是秒，而是时间刻度。只有pts加上time_base两者同时在一起，才能表达出时间是多少。

比如：pts=20个刻度，time_base={1,10} 每一个刻度是1/10厘米。所以物体的长度为 pts*time_base=20*1/10=2 厘米

av_q2d(time_base)=每个刻度是多少秒
此时你应该不难理解 pts*av_q2d(time_base) 才是帧的显示时间戳。

- 下面理解时间基的转换，为什么要有时间基转换？

首先，不同的封装格式， timebase 是不一样的。
另外，整个转码过程，不同的数据状态对应的时间基也不一致。
拿 mpegts 封装格式 25fps 来说（只说视频，音频大致一样，但也略有不同）。非压缩时候的数据（即YUV或者其它），在ffmpeg中对应的结构体为 AVFrame, 它的时间基为 AVCodecContext 的 time_base , AVRational{1,25}。

压缩后的数据（对应的结构体为AVPacket）对应的时间基为 AVStream 的 time_base  ， AVRational{1,90000}。

因为数据状态不同，时间基不一样，所以我们必须转换，在1/25时间刻度下占10格，在 1/90000 下是占多少格。这就是 pts 的转换。

根据pts来计算一桢在整个视频中的时间位置：

timestamp(秒) = pts * av_q2d(st->time_base)

duration 和 pts 单位一样，duration 表示当前帧的持续时间占多少格。或者理解是两帧的间隔时间是占多少格。一定要理解单位。

pts：格子数
av_q2d(st->time_base): 秒/格

计算视频长度：time(秒) = st->duration * av_q2d(st->time_base)

ffmpeg内部的时间与标准的时间转换方法：

ffmpeg内部的时间戳 = AV_TIME_BASE * time(秒)
AV_TIME_BASE_Q=1/AV_TIME_BASE

av_rescale_q(int64_t a, AVRational bq, AVRational cq) `a*bq/cq`

这个函数的作用是计算 `a*bq/cq` 来把时间戳从一个时间基调整到另外一个时间基。
在进行时间基转换的时候，应该首选这个函数，因为它可以避免溢出的情况发生。
函数表示在bq下的占a个格子，在cq下是多少。

关于音频pts的计算：
音频 sample_rate:samples per second，即采样率，表示每秒采集多少采样点。
比如 44100HZ，就是一秒采集44100 个 sample.
即每个 sample 的时间是 1/44100 秒

一个音频帧的 AVFrame 有 nb_samples 个 sample，所以一个 AVFrame 耗时是 nb_samples*（1/44100）秒
即标准时间下 duration_s=nb_samples*（1/44100）秒，
转换成 AVStream 时间基下
duration=duration_s / av_q2d(st->time_base)
基于 st->time_base 的 num 值一般等于采样率,所以 duration=nb_samples.
pts=n*duration=n*nb_samples
